{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, do these things for yourself.  Nobody else.  Get the most out of it for ourselves and ourselves only.\n",
    "\n",
    "All Labs have solutions now so we can go through "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff to do\n",
    "\n",
    "Original Problem Statement: Through sentimitation, can we learn which channels have the most positive and negative communities?\n",
    "    Relevance: By identifying which channels are putting out more positivity and which are putting out less positivity will help creaters improve on such things should they wish to.  It will also help Youtube support the channels which or more positive, which will help improve the brand of youtube by making it present more as a place which can foster positivity rather than a cesspool of potential negativity.\n",
    "    Add Relevance: Why people should care and why this matter.\n",
    "    - Sentimentality MEtric: between -1 and 1 as given by the Textblobs\n",
    "\n",
    "\n",
    "Milestone 1: Sentimitize each video\n",
    "Milestone 2: Sentimitize all comment on all video of one user\n",
    "Milestone #: Clean timeseries and change video_id's to video names\n",
    "\n",
    "Bonus     1: Latient Dirilech Analysis\n",
    "Bonus     2: Topic system\n",
    "Bonus     #: Function to guess/estimate how many comments a channel has\n",
    "Bonus     3: Model prediction how many comments will happen over time (based on views and topic)\n",
    "Bonus     4: Model prediction sentiment on a given video (Based on topic)\n",
    "                        \n",
    "\n",
    "Next Level:\n",
    "* EDA\n",
    "* Create function to calculate number of comments to be scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore:\n",
    "\t- Pairplot/correlation table with top 50% of results (Keeping it white box)\n",
    "\t- Insert LDA, if only for the EDA\n",
    "\t- Continuing to attempt to add topic modeling        (Difficulty adding as feature)\n",
    "\n",
    "    - Performing PCA                                     (Would make black box)\n",
    "\t- Check again with information returned from API     (Wouldn't be demographic, but might be something)\n",
    "    - Gather Massive Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importations and Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                    # Imports for Standard Junk\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "                                                    # Imports for Natural Language Processing\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from textblob import TextBlob\n",
    "#import json\n",
    "#from bs4 import BeautifulSoup\n",
    "                                                    # Imports for Plotting & Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "                                                    # Imports for Modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path Start: Json Scraping\n",
    "Sentiment:\n",
    "    Sentamentize videos\n",
    "    Sentamentize Channels\n",
    "    Correlations to sentament\n",
    "    Import more data\n",
    "    Compair sentament to other data of other channels\n",
    "    \n",
    "Topic Selection:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiations of the Preprocessor and Count Vectorizer\n",
    "from nltk.corpus import stopwords\n",
    "#    stop_words = stopwords.words(\"english\")\n",
    "#    return \" \".join([lemmer.lemmatize(word) for word in tokens if not word in stop_words])\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-zA-Z]',' ', text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    return \" \".join([lemmer.lemmatize(word) for word in tokens if len(word) > 1 and not word in stop_words])\n",
    "cvec = CountVectorizer(analyzer = \"word\",\n",
    "                       min_df = 2,\n",
    "                       preprocessor = preprocess,\n",
    "                       stop_words = 'english') \n",
    "\n",
    "\n",
    "cvec_three = CountVectorizer(analyzer = \"word\",\n",
    "                       min_df = 2,\n",
    "                       preprocessor = preprocess,\n",
    "                       stop_words = 'english',\n",
    "                       ngram_range = (3,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Loading up all of the Channel Comments into dataframes\n",
    "Aliens_Guide         = pd.read_csv('./data/Aliens_Guide_9_25')\n",
    "Allison              = pd.read_csv('./data/Allisons_Channel_Comments_9_25')\n",
    "Hi_Im_Mary_Mary      = pd.read_csv('./data/Hi_Im_Mary_Mary_9_25')\n",
    "Maggie_Mae_Fish      = pd.read_csv('./data/Maggie_Mae_Fish_9_25')\n",
    "LaRon_Readus         = pd.read_csv('./data/LaRon_Readus_9_25')\n",
    "Strange_Aeons        = pd.read_csv('./data/Strange_Aeons_9_25')\n",
    "MovieBob             = pd.read_csv('./data/MovieBob_9_25')\n",
    "Sammus               = pd.read_csv('./data/Sammus_9_25')\n",
    "Shodan               = pd.read_csv('./data/Shodan_9_25')\n",
    "Saraj_Raval          = pd.read_csv('./data/Saraj_Raval_9_27_attempt3')\n",
    "Nyx_Fears            = pd.read_csv('./data/Nyx_Fears_9_25')\n",
    "Petscop              = pd.read_csv('./data/Petscop_9_25')\n",
    "NerdSync             = pd.read_csv('./data/NerdSync_9_25')\n",
    "Everyman_HYBRID      = pd.read_csv('./data/Everyman_HYBRID_9_25')\n",
    "Small_Beans          = pd.read_csv('./data/Small_Beans_9_25')\n",
    "Some_More_News       = pd.read_csv('./data/Some_More_News_9_25')\n",
    "The_Gaming_Brit_Show = pd.read_csv('./data/The_Gaming_Brit_Show_9_27')\n",
    "Super_Bunnyhop       = pd.read_csv('./data/Super_Bunnyhop_9_25')\n",
    "# Following added on Oct 21\n",
    "ContraPoints         = pd.read_csv('./data/ContraPoints_Channel_Comments_10_17')\n",
    "Lindsay_Ellis        = pd.read_csv('./data/Lindsay_Ellis_10_18')\n",
    "Queer_Kid_Stuff      = pd.read_csv('./data/Queer_Kid_Stuff_10_18')\n",
    "The_Golden_One       = pd.read_csv('./data/The_Golden_One_10_18')\n",
    "Ant_Dude             = pd.read_csv('./data/Ant_Dude_10_18')\n",
    "Black_Pilled         = pd.read_csv('./data/Black_Pilled_10_18')\n",
    "Magog_of_Morskar     = pd.read_csv('./data/Magog_of_Morskar_10_18')\n",
    "Polygon              = pd.read_csv('./data/Polygon_10_18')\n",
    "Radekken             = pd.read_csv('./data/Radekken_10_18')\n",
    "CinemaWins           = pd.read_csv('./data/CinemaWins_10_19')\n",
    "CinemaSins           = pd.read_csv('./data/CinemaSins_10_19')\n",
    "#                     = pd.read_csv('./data/')\n",
    "#                     = pd.read_csv('./data/')\n",
    "#                     = pd.read_csv('./data/')\n",
    "#                     = pd.read_csv('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549795\n"
     ]
    }
   ],
   "source": [
    "# First list is for all the channel names, second list is of all the dataframes of the channels in a list\n",
    "channel_names = ['Aliens_Guide', 'Allison', 'Ant_Dude', 'Black_Pilled', \n",
    "                 'CinemaSins', 'CinemaWins', 'ContraPoints', \n",
    "                 'Everyman_HYBRID', 'Hi_Im_Mary_Mary', 'LaRon_Readus', 'Lindsay_Ellis', \n",
    "                 'Maggie_Mae_Fish', 'Magog_of_Morskar', 'MovieBob', 'NerdSync', 'Nyx_Fears', \n",
    "                 'Petscop', 'Polygon', 'Queer_Kid_Stuff', 'Radekken', 'Sammus', 'Shodan', \n",
    "                 'Small_Beans', 'Some_More_News', 'Strange_Aeons', 'Super_Bunnyhop', \n",
    "                 'The_Gaming_Brit_Show', 'The_Golden_One']\n",
    "channels_obtained = [Aliens_Guide, Allison, Ant_Dude, Black_Pilled, \n",
    "                     CinemaSins, CinemaWins, ContraPoints, \n",
    "                     Everyman_HYBRID, Hi_Im_Mary_Mary, LaRon_Readus, Lindsay_Ellis, \n",
    "                     Maggie_Mae_Fish, Magog_of_Morskar, MovieBob, NerdSync, Nyx_Fears, \n",
    "                     Petscop,Polygon, Queer_Kid_Stuff, Radekken, Sammus, Shodan, \n",
    "                     Small_Beans, Some_More_News, Strange_Aeons, Super_Bunnyhop, \n",
    "                     The_Gaming_Brit_Show, The_Golden_One]\n",
    "\n",
    "# Current number of comments in all the channels that we currently have.\n",
    "count = 0\n",
    "for i in channels_obtained:\n",
    "    count += i.shape[0]\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimentality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a sentimization function\n",
    "\n",
    "def Sentamentize(text):\n",
    "    return TextBlob(str(text)).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Aliens_Guide\n",
      "27 Allison\n",
      "26 Ant_Dude\n",
      "25 Black_Pilled\n",
      "24 CinemaSins\n",
      "23 CinemaWins\n",
      "22 ContraPoints\n",
      "21 Everyman_HYBRID\n",
      "20 Hi_Im_Mary_Mary\n",
      "19 LaRon_Readus\n",
      "18 Lindsay_Ellis\n",
      "17 Maggie_Mae_Fish\n",
      "16 Magog_of_Morskar\n",
      "15 MovieBob\n",
      "14 NerdSync\n",
      "13 Nyx_Fears\n",
      "12 Petscop\n",
      "11 Polygon\n",
      "10 Queer_Kid_Stuff\n",
      "9 Radekken\n",
      "8 Sammus\n",
      "7 Shodan\n",
      "6 Small_Beans\n",
      "5 Some_More_News\n",
      "4 Strange_Aeons\n",
      "3 Super_Bunnyhop\n",
      "2 The_Gaming_Brit_Show\n",
      "1 The_Golden_One\n"
     ]
    }
   ],
   "source": [
    "# Adding Sentimization to each row of all the existant dataframes\n",
    "\n",
    "count = 0\n",
    "for df in channels_obtained:\n",
    "    print(len(channels_obtained)-count, channel_names[count])\n",
    "    df['sentiment_textblob'] = df.apply(lambda x: pd.Series(Sentamentize(x),\n",
    "                                                            index=['text']),\n",
    "                                                            axis=1)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliens_Guide 0.32087793017115235\n",
      "Allison 0.39108676046176044\n",
      "Ant_Dude 0.26618182570828824\n",
      "Black_Pilled 0.26857607052564225\n",
      "CinemaSins 0.26229829108655317\n",
      "CinemaWins 0.3104749125581729\n",
      "ContraPoints 0.29610938640502754\n",
      "Everyman_HYBRID 0.27206207241541824\n",
      "Hi_Im_Mary_Mary 0.29798546273410714\n",
      "LaRon_Readus 0.2949830476880584\n",
      "Lindsay_Ellis 0.29492783898301006\n",
      "Maggie_Mae_Fish 0.3457911574076005\n",
      "Magog_of_Morskar 0.2690056508754031\n",
      "MovieBob 0.28133110354098173\n",
      "NerdSync 0.29828911435786365\n",
      "Nyx_Fears 0.3286713994964437\n",
      "Petscop 0.25405123775820965\n",
      "Polygon 0.2045516500455746\n",
      "Queer_Kid_Stuff 0.2598593964334704\n",
      "Radekken 0.3039413402264928\n",
      "Sammus 0.3562067275436523\n",
      "Shodan 0.31600742304642127\n",
      "Small_Beans 0.31223313550288045\n",
      "Some_More_News 0.29285319756676076\n",
      "Strange_Aeons 0.26617750920026256\n",
      "Super_Bunnyhop 0.26944546654274304\n",
      "The_Gaming_Brit_Show 0.1509558670603739\n",
      "The_Golden_One 0.28038346397353753\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for df in channels_obtained:\n",
    "    print(channel_names[count], df['sentiment_textblob'].mean())\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/terra/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cvec_MovieBob = CountVec(MovieBob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sentament_textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3062\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3063\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentament_textblob'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-354eee9d24f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMovieBob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentament_textblob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2683\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2690\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2692\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3063\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3065\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentament_textblob'"
     ]
    }
   ],
   "source": [
    "MovieBob['sentament_textblob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_MovieBob['sentiment'] = MovieBob['sentiment_textblob']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvec_MovieBob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c3d29c1d19f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlin_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'columns_etc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvec_MovieBob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentament'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvec_MovieBob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentament'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cvec_MovieBob' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "features = ['columns_etc']\n",
    "X = cvec_MovieBob.drop('sentament', axis = 1)\n",
    "y = cvec_MovieBob['sentament']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# Alt-code for SS\n",
    "lin_reg.fit(X_train, y_train) #these are the paramaeters for predictions\n",
    "lin_reg.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "X = MovieBob.drop('sentiment_textblob', axis = 1)\n",
    "y = MovieBob['sentiment_textblob']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# Alt-code for SS\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()         \n",
    "X_train_scaled = ss.fit_transform(X_train)  # Fit & Transform XTrain\n",
    "X_test_scaled = ss.transform(X_test)        # Transform XTest\n",
    "\n",
    "lin_reg.fit(X_train_scaled, y_train) #these are the paramaeters for predictions\n",
    "lin_reg.score(X_test_scaled,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.592659573403085e+27"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "features = ['columns_etc']\n",
    "X = cvec_MovieBob.drop('sentament', axis = 1)\n",
    "y = cvec_MovieBob['sentament']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# Alt-code for SS\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()         \n",
    "X_train_scaled = ss.fit_transform(X_train)  # Fit & Transform XTrain\n",
    "X_test_scaled = ss.transform(X_test)        # Transform XTest\n",
    "\n",
    "lin_reg.fit(X_train_scaled, y_train) #these are the paramaeters for predictions\n",
    "lin_reg.score(X_test_scaled,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>published_time</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>is_public</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I think snyder may hate  superman more than fr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-09-25T14:35:16.000Z</td>\n",
       "      <td>magnasupreme</td>\n",
       "      <td>UClgdpWUFTdMCycAP9epZZdQ</td>\n",
       "      <td>F9juReoJxI0</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugy94nV74jqnp5GWYU94AaABAg</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ah you're the escapist leech.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-09-25T12:40:24.000Z</td>\n",
       "      <td>Nathan</td>\n",
       "      <td>UCojZYAHsyKtmmPAp1AhSk3Q</td>\n",
       "      <td>RdkYCpQ2TNY</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugx7pD5arLOlb-pc48Z4AaABAg</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why you gotta ruin YouTube as my culture Bob :(</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-09-25T08:04:14.000Z</td>\n",
       "      <td>Justin M</td>\n",
       "      <td>UCmIQGNT68vn9smJREtngedg</td>\n",
       "      <td>jrusTEvgxgI</td>\n",
       "      <td>True</td>\n",
       "      <td>UgxjSMC48JpT6AzqwMp4AaABAg</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Going rampant is fucking dumbass the new remak...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-09-24T18:27:51.000Z</td>\n",
       "      <td>Max Nyström</td>\n",
       "      <td>UCnitjL9AIhyNsg-wvIsiOXw</td>\n",
       "      <td>BPoILjs6BYI</td>\n",
       "      <td>True</td>\n",
       "      <td>UgyRbNXjv36cX2wbKNl4AaABAg</td>\n",
       "      <td>0.096591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It figures that one massive manchild would giv...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-09-24T18:23:49.000Z</td>\n",
       "      <td>ReverendSyn</td>\n",
       "      <td>UCdluLm6lTqnWGJXD3oR-2hw</td>\n",
       "      <td>oLvux3kpu1o</td>\n",
       "      <td>True</td>\n",
       "      <td>UgwM3C2AP-_fVUcBAGV4AaABAg</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  likes  replies  \\\n",
       "0  I think snyder may hate  superman more than fr...    0.0      0.0   \n",
       "1                      Ah you're the escapist leech.    0.0      0.0   \n",
       "2    Why you gotta ruin YouTube as my culture Bob :(    0.0      0.0   \n",
       "3  Going rampant is fucking dumbass the new remak...    0.0      0.0   \n",
       "4  It figures that one massive manchild would giv...    0.0      0.0   \n",
       "\n",
       "             published_time   author_name                 author_id  \\\n",
       "0  2018-09-25T14:35:16.000Z  magnasupreme  UClgdpWUFTdMCycAP9epZZdQ   \n",
       "1  2018-09-25T12:40:24.000Z        Nathan  UCojZYAHsyKtmmPAp1AhSk3Q   \n",
       "2  2018-09-25T08:04:14.000Z      Justin M  UCmIQGNT68vn9smJREtngedg   \n",
       "3  2018-09-24T18:27:51.000Z   Max Nyström  UCnitjL9AIhyNsg-wvIsiOXw   \n",
       "4  2018-09-24T18:23:49.000Z   ReverendSyn  UCdluLm6lTqnWGJXD3oR-2hw   \n",
       "\n",
       "      video_id is_public                  comment_id  sentiment_textblob  \n",
       "0  F9juReoJxI0      True  Ugy94nV74jqnp5GWYU94AaABAg            0.016667  \n",
       "1  RdkYCpQ2TNY      True  Ugx7pD5arLOlb-pc48Z4AaABAg            0.350000  \n",
       "2  jrusTEvgxgI      True  UgxjSMC48JpT6AzqwMp4AaABAg           -0.200000  \n",
       "3  BPoILjs6BYI      True  UgyRbNXjv36cX2wbKNl4AaABAg            0.096591  \n",
       "4  oLvux3kpu1o      True  UgwM3C2AP-_fVUcBAGV4AaABAg            0.175000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MovieBob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.592659573403085e+27"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "features = ['columns_etc']\n",
    "X = MovieBob.drop('sentament', axis = 1)\n",
    "y = MovieBob['sentament']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# Alt-code for SS\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()         \n",
    "X_train_scaled = ss.fit_transform(X_train)  # Fit & Transform XTrain\n",
    "X_test_scaled = ss.transform(X_test)        # Transform XTest\n",
    "\n",
    "lin_reg.fit(X_train_scaled, y_train) #these are the paramaeters for predictions\n",
    "lin_reg.score(X_test_scaled,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.18538887881918e+23"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()         \n",
    "X_train_scaled = ss.fit_transform(X_train)  # Fit & Transform XTrain\n",
    "X_test_scaled = ss.transform(X_test)        # Transform XTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>is_public</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-WNfFu4AgxE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.488889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3OwnPr_5JJA</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.271429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4j5d06YbU1o</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JqmWhozWOhw</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.254167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeOtZghc194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LbFhwWeysDI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MgP_6GipDCU</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OIS4h-zqHFo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-0fWqQe2w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QOD57KWArzM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flSTkbgISAw</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.244583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oeTIb49Pgm0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vcJgTzDBXko</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.437370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veyfNvN-Dv8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             likes  replies  is_public  sentiment_textblob\n",
       "video_id                                                  \n",
       "-WNfFu4AgxE      0        0       True            0.488889\n",
       "3OwnPr_5JJA      0        0       True           -0.271429\n",
       "4j5d06YbU1o      0        2       True            0.350000\n",
       "JqmWhozWOhw      0        0       True            0.254167\n",
       "KeOtZghc194      0        0       True            0.616667\n",
       "LbFhwWeysDI      0        0       True            0.475000\n",
       "MgP_6GipDCU      0        0       True            0.350000\n",
       "None             0        0       True            0.355556\n",
       "OIS4h-zqHFo      0        0       True            0.475000\n",
       "PT-0fWqQe2w      0        0       True            0.487500\n",
       "QOD57KWArzM      0        0       True            0.637500\n",
       "flSTkbgISAw      0        0       True            0.244583\n",
       "oeTIb49Pgm0      0        0       True            0.350000\n",
       "vcJgTzDBXko      0        0       True            0.437370\n",
       "veyfNvN-Dv8      0        0       True            0.675000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Allison.groupby(['video_id']).mean()\n",
    "\n",
    "#df.groupby([video_id]).avg(df['sentiment_textblob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    incels_test = pd.read_csv('../../project-3/braincels_9_9_400')\n",
    "except:\n",
    "    incels_test = pd.read_csv('../../5th_week/project-3/braincels_9_9_400.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031530365769496214\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 3, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3062\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3063\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentiment_textblob'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   4242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4243\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4244\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3065\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentiment_textblob'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-26f0d7798635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSentamentize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mincels_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_textblob'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincels_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSentamentize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincels_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selftext'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                             \u001b[0;31m#index=['title']),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                             \u001b[0;31m#axis=1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3191\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3192\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2598\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   4244\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4245\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4246\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4247\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   4345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4346\u001b[0m         block = make_block(values=value, ndim=self.ndim,\n\u001b[0;32m-> 4347\u001b[0;31m                            placement=slice(loc, loc + 1))\n\u001b[0m\u001b[1;32m   4348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4349\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   3203\u001b[0m                      placement=placement, dtype=dtype)\n\u001b[1;32m   3204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3205\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3207\u001b[0m \u001b[0;31m# TODO: flexible with index=None and/or items=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    123\u001b[0m             raise ValueError(\n\u001b[1;32m    124\u001b[0m                 \u001b[0;34m'Wrong number of items passed {val}, placement implies '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 '{mgr}'.format(val=len(self.values), mgr=len(self.mgr_locs)))\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 3, placement implies 1"
     ]
    }
   ],
   "source": [
    "print(Sentamentize(incels_test))\n",
    "incels_test['sentiment_textblob'] = incels_test.dropna().apply(lambda x: pd.Series(Sentamentize(incels_test['selftext'][x])))\n",
    "                                                            #index=['title']),\n",
    "                                                            #axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.075000\n",
       "2      0.175000\n",
       "19     0.350000\n",
       "21    -0.027500\n",
       "27     0.076020\n",
       "32    -0.170139\n",
       "35    -0.320000\n",
       "38     0.080000\n",
       "44    -0.100000\n",
       "46    -0.098864\n",
       "49     0.024359\n",
       "53     0.000000\n",
       "57    -0.045238\n",
       "62    -0.004688\n",
       "63    -0.280952\n",
       "69    -0.177273\n",
       "73    -0.012500\n",
       "74    -0.207692\n",
       "77     0.136364\n",
       "78     0.002500\n",
       "86     0.000000\n",
       "88     0.150000\n",
       "95     0.041667\n",
       "97     0.046333\n",
       "101    0.150000\n",
       "103    0.168750\n",
       "107    0.216667\n",
       "112    0.017560\n",
       "113   -0.035714\n",
       "117   -0.184444\n",
       "         ...   \n",
       "919    0.000000\n",
       "920    0.000000\n",
       "921    0.178571\n",
       "922    0.028889\n",
       "924    0.171296\n",
       "927   -0.375000\n",
       "928    0.500000\n",
       "929    0.014008\n",
       "930   -0.104242\n",
       "931    0.192857\n",
       "932    0.285185\n",
       "941    0.072222\n",
       "942    0.370312\n",
       "944    0.250000\n",
       "947    0.412500\n",
       "949    0.000000\n",
       "951    0.000000\n",
       "952   -0.284375\n",
       "956   -0.155556\n",
       "957    0.444444\n",
       "959   -0.245000\n",
       "961    0.000000\n",
       "966   -0.358333\n",
       "967    0.357143\n",
       "968   -0.260526\n",
       "970   -0.086458\n",
       "972   -0.156944\n",
       "973    0.250000\n",
       "979   -0.066667\n",
       "980    0.000000\n",
       "Length: 457, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incels_test.dropna().apply(lambda row: Sentamentize(incels_test['selftext'][row]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3062\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3063\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-93b99647be86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mincels_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2683\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2690\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2692\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3063\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3065\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "incels_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentamentize(incels_test['selftext'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "      <th>sentiment_textblob_st</th>\n",
       "      <th>sentiment_textblob_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goodbye, guys. I leave you all with this song.</td>\n",
       "      <td>I was going to do this on a throwaway and just...</td>\n",
       "      <td>Braincels</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Found a false flag IncelTear/AHS user. Watch o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Braincels</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First day of kindergarten tomorrow? Any advice...</td>\n",
       "      <td>Sup guys I'm a 4 year old incel (got rejected ...</td>\n",
       "      <td>Braincels</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joblless Female Geting Rejected</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Braincels</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“The past is the past guys”. Get over it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Braincels</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0     Goodbye, guys. I leave you all with this song.   \n",
       "1  Found a false flag IncelTear/AHS user. Watch o...   \n",
       "2  First day of kindergarten tomorrow? Any advice...   \n",
       "3                    Joblless Female Geting Rejected   \n",
       "4           “The past is the past guys”. Get over it   \n",
       "\n",
       "                                            selftext  subreddit  \\\n",
       "0  I was going to do this on a throwaway and just...  Braincels   \n",
       "1                                                NaN  Braincels   \n",
       "2  Sup guys I'm a 4 year old incel (got rejected ...  Braincels   \n",
       "3                                                NaN  Braincels   \n",
       "4                                                NaN  Braincels   \n",
       "\n",
       "   sentiment_textblob  sentiment_textblob_st  sentiment_textblob_title  \n",
       "0               0.000                  0.000                     0.000  \n",
       "1              -0.400                 -0.400                    -0.400  \n",
       "2               0.175                  0.175                     0.175  \n",
       "3               0.250                  0.250                     0.250  \n",
       "4              -0.250                 -0.250                    -0.250  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incels_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountVec(df):            # A quick and easy function for Count Vectorization into a data frame!\n",
    "    return pd.DataFrame(cvec.fit_transform(df['text']).todense(), columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for df in channels_obtained: # Dropping any rows of NaN.  There were less than 10 between all df's\n",
    "    print(channel_names[count],df.isna().sum().sum())\n",
    "    df.shape()\n",
    "    df['text'].dropna(inplace=True)\n",
    "    df.shape()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/17 Done\n",
      "11/17 Done\n",
      "15/17 Done\n",
      "16/17 Done\n"
     ]
    }
   ],
   "source": [
    "                             # Count Vectorizing all current channels.\n",
    "cvec_Aliens_Guide = CountVec(Aliens_Guide)\n",
    "cvec_Allison = CountVec(Allison)\n",
    "cvec_Everyman_HYBRID = CountVec(Everyman_HYBRID)\n",
    "cvec_Hi_Im_Mary_Mary = CountVec(Hi_Im_Mary_Mary)\n",
    "cvec_LaRon_Readus = CountVec(LaRon_Readus)\n",
    "print('5/26 Done')\n",
    "cvec_Maggie_Mae_Fish = CountVec(Maggie_Mae_Fish)\n",
    "cvec_MovieBob = CountVec(MovieBob)\n",
    "cvec_NerdSync = CountVec(NerdSync)\n",
    "cvec_Nyx_Fears = CountVec(Nyx_Fears)\n",
    "cvec_Petscop = CountVec(Petscop)\n",
    "cvec_Sammus = CountVec(Sammus)\n",
    "print('11/26 Done')\n",
    "cvec_Shodan = CountVec(Shodan)\n",
    "cvec_Small_Beans = CountVec(Small_Beans)\n",
    "cvec_Some_More_News = CountVec(Some_More_News)\n",
    "cvec_Strange_Aeons = CountVec(Strange_Aeons)\n",
    "print('15/26 Done')\n",
    "cvec_Super_Bunnyhop = CountVec(Super_Bunnyhop)\n",
    "print('16/26 Done')\n",
    "cvec_The_Gaming_Brit_Show = CountVec(The_Gaming_Brit_Show)\n",
    "cvec_ContraPoints         = CountVec(ContraPoints)\n",
    "cvec_Lindsay_Ellis        = CountVec(Lindsay_Ellis)\n",
    "cvec_Queer_Kid_Stuff      = CountVec(Queer_Kid_Stuff)\n",
    "print('20/26 Done')\n",
    "cvec_The_Golden_One       = CountVec(The_Golden_One)\n",
    "cvec_Ant_Dude             = CountVec(Ant_Dude)\n",
    "cvec_Black_Pilled         = CountVec(Black_Pilled)\n",
    "cvec_Magog_of_Morskar     = CountVec(Magog_of_Morskar)\n",
    "print('24/26 Done')\n",
    "cvec_Polygon              = CountVec(Polygon)\n",
    "print('25/26 Done')\n",
    "cvec_Radekken             = CountVec(Radekken)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "channels_cveced = [cvec_Aliens_Guide,\n",
    " cvec_Allison, cvec_Everyman_HYBRID, cvec_Hi_Im_Mary_Mary, cvec_LaRon_Readus,\n",
    " cvec_Maggie_Mae_Fish, cvec_MovieBob, cvec_NerdSync, cvec_Nyx_Fears,\n",
    " cvec_Petscop, cvec_Sammus, cvec_Shodan, cvec_Small_Beans, cvec_Some_More_News,\n",
    " cvec_Strange_Aeons, cvec_Super_Bunnyhop, cvec_The_Gaming_Brit_Show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0f01842241af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchannels_cveced\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./cvec_data/cvec_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchannel_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1745\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    275\u001b[0m                                   \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                                   \u001b[0mdate_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                                   quoting=self.quoting)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mto_native_types\u001b[0;34m(self, slicer, na_rep, quoting, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_object\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for df in channels_cveced:\n",
    "    df.to_csv('./cvec_data/cvec_' + channel_names[count], index=False)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_ContraPoints         = CountVec(ContraPoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just Some Fun Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_Everyman_HYBRID['ಠ_ಠ'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation\n",
    "\n",
    " Idea: Sentament Based on LDA\n",
    "         LDA Each row is a video\n",
    "         3 top topics\n",
    "         5 words per topic\n",
    "         cvec type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation      # Import the LDA Model\n",
    "import warnings                                                  # Skip Depreccion Warnings\n",
    "def LDA_spelled_out(df, num_topics = 3, num_words = 5):\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics)\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    cvec.fit(df['text'])\n",
    "    text = cvec.transform(df['text'])\n",
    "    lda.fit(text)\n",
    "    for ix, topic in enumerate(lda.components_):\n",
    "        print('Topic ', ix + 1)\n",
    "        top_words = [cvec.get_feature_names()[i] for i in lda.components_[ix].argsort()[:-num_words - 1:-1]]\n",
    "        print('\\n'.join(top_words))\n",
    "        print('')\n",
    "    return\n",
    "        \n",
    "#    return pd.DataFrame({'words':cvec.get_feature_names(),            # Actually printing the LDA stuff\n",
    "#             'LDA score': lda.components_[0]}).set_index('words').sort_values('LDA score',\n",
    "#                                                                              ascending =False).head(5)\n",
    "\n",
    "#cvec = CountVectorizer(analyzer = \"word\",\n",
    "#                             min_df = 2,\n",
    "#                             tokenizer = tokenizer.tokenize,\n",
    "#                             preprocessor = None,\n",
    "#                             stop_words = 'english') \n",
    "#lda = LatentDirichletAllocation(n_components=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliens_Guide\n",
      "Topic  1\n",
      "people\n",
      "incredibles\n",
      "garyx\n",
      "time\n",
      "great\n",
      "\n",
      "Topic  2\n",
      "turkey\n",
      "monster\n",
      "mean\n",
      "spaghetti\n",
      "say\n",
      "\n",
      "Topic  3\n",
      "movie\n",
      "like\n",
      "alien\n",
      "guide\n",
      "video\n",
      "\n",
      "\n",
      "Allison\n",
      "Topic  1\n",
      "viola\n",
      "music\n",
      "great\n",
      "love\n",
      "play\n",
      "\n",
      "Topic  2\n",
      "music\n",
      "nice\n",
      "girl\n",
      "work\n",
      "amazing\n",
      "\n",
      "Topic  3\n",
      "violin\n",
      "nice\n",
      "guy\n",
      "music\n",
      "sheet\n",
      "\n",
      "\n",
      "Everyman_HYBRID\n",
      "Topic  1\n",
      "video\n",
      "shit\n",
      "fuck\n",
      "slenderman\n",
      "marble\n",
      "\n",
      "Topic  2\n",
      "evan\n",
      "like\n",
      "rake\n",
      "slenderman\n",
      "habit\n",
      "\n",
      "Topic  3\n",
      "slendy\n",
      "man\n",
      "slender\n",
      "guy\n",
      "need\n",
      "\n",
      "\n",
      "Hi_Im_Mary_Mary\n",
      "Topic  1\n",
      "mary\n",
      "hi\n",
      "hello\n",
      "love\n",
      "que\n",
      "\n",
      "Topic  2\n",
      "happy\n",
      "new\n",
      "video\n",
      "year\n",
      "real\n",
      "\n",
      "Topic  3\n",
      "garden\n",
      "mary\n",
      "think\n",
      "like\n",
      "know\n",
      "\n",
      "\n",
      "LaRon_Readus\n",
      "Topic  1\n",
      "people\n",
      "time\n",
      "like\n",
      "new\n",
      "watch\n",
      "\n",
      "Topic  2\n",
      "like\n",
      "movie\n",
      "video\n",
      "venom\n",
      "film\n",
      "\n",
      "Topic  3\n",
      "like\n",
      "movie\n",
      "character\n",
      "really\n",
      "think\n",
      "\n",
      "\n",
      "Maggie_Mae_Fish\n",
      "Topic  1\n",
      "video\n",
      "great\n",
      "maggie\n",
      "reaction\n",
      "love\n",
      "\n",
      "Topic  2\n",
      "movie\n",
      "like\n",
      "love\n",
      "think\n",
      "film\n",
      "\n",
      "Topic  3\n",
      "like\n",
      "look\n",
      "lol\n",
      "episode\n",
      "god\n",
      "\n",
      "\n",
      "MovieBob\n",
      "Topic  1\n",
      "movie\n",
      "like\n",
      "people\n",
      "film\n",
      "think\n",
      "\n",
      "Topic  2\n",
      "right\n",
      "gunn\n",
      "disney\n",
      "people\n",
      "james\n",
      "\n",
      "Topic  3\n",
      "bob\n",
      "like\n",
      "video\n",
      "good\n",
      "really\n",
      "\n",
      "\n",
      "NerdSync\n",
      "Topic  1\n",
      "like\n",
      "video\n",
      "spider\n",
      "man\n",
      "make\n",
      "\n",
      "Topic  2\n",
      "costume\n",
      "marvel\n",
      "need\n",
      "know\n",
      "mask\n",
      "\n",
      "Topic  3\n",
      "kid\n",
      "spiderman\n",
      "theme\n",
      "black\n",
      "best\n",
      "\n",
      "\n",
      "Nyx_Fears\n",
      "Topic  1\n",
      "movie\n",
      "like\n",
      "film\n",
      "really\n",
      "think\n",
      "\n",
      "Topic  2\n",
      "love\n",
      "nyx\n",
      "movie\n",
      "video\n",
      "review\n",
      "\n",
      "Topic  3\n",
      "video\n",
      "love\n",
      "happy\n",
      "like\n",
      "really\n",
      "\n",
      "\n",
      "Petscop\n",
      "Topic  1\n",
      "paul\n",
      "like\n",
      "care\n",
      "think\n",
      "marvin\n",
      "\n",
      "Topic  2\n",
      "game\n",
      "video\n",
      "theory\n",
      "paul\n",
      "nifty\n",
      "\n",
      "Topic  3\n",
      "petscop\n",
      "matpat\n",
      "fuck\n",
      "loss\n",
      "hey\n",
      "\n",
      "\n",
      "Sammus\n",
      "Topic  1\n",
      "love\n",
      "video\n",
      "song\n",
      "great\n",
      "music\n",
      "\n",
      "Topic  2\n",
      "like\n",
      "need\n",
      "think\n",
      "life\n",
      "sound\n",
      "\n",
      "Topic  3\n",
      "dope\n",
      "awesome\n",
      "thanks\n",
      "sammus\n",
      "rapper\n",
      "\n",
      "\n",
      "Shodan\n",
      "Topic  1\n",
      "vid\n",
      "burn\n",
      "guy\n",
      "na\n",
      "gon\n",
      "\n",
      "Topic  2\n",
      "nice\n",
      "book\n",
      "good\n",
      "got\n",
      "lol\n",
      "\n",
      "Topic  3\n",
      "yes\n",
      "love\n",
      "twilight\n",
      "vampire\n",
      "song\n",
      "\n",
      "\n",
      "Small_Beans\n",
      "Topic  1\n",
      "movie\n",
      "like\n",
      "love\n",
      "people\n",
      "stuff\n",
      "\n",
      "Topic  2\n",
      "game\n",
      "like\n",
      "think\n",
      "story\n",
      "thing\n",
      "\n",
      "Topic  3\n",
      "cracked\n",
      "guy\n",
      "love\n",
      "video\n",
      "content\n",
      "\n",
      "\n",
      "Some_More_News\n",
      "Topic  1\n",
      "news\n",
      "cody\n",
      "video\n",
      "love\n",
      "good\n",
      "\n",
      "Topic  2\n",
      "great\n",
      "cody\n",
      "like\n",
      "youtube\n",
      "straw\n",
      "\n",
      "Topic  3\n",
      "people\n",
      "trump\n",
      "right\n",
      "like\n",
      "left\n",
      "\n",
      "\n",
      "Strange_Aeons\n",
      "Topic  1\n",
      "people\n",
      "like\n",
      "love\n",
      "gay\n",
      "god\n",
      "\n",
      "Topic  2\n",
      "teacher\n",
      "like\n",
      "crush\n",
      "school\n",
      "year\n",
      "\n",
      "Topic  3\n",
      "girl\n",
      "time\n",
      "video\n",
      "long\n",
      "furby\n",
      "\n",
      "\n",
      "Super_Bunnyhop\n",
      "Topic  1\n",
      "game\n",
      "sonic\n",
      "year\n",
      "thought\n",
      "best\n",
      "\n",
      "Topic  2\n",
      "game\n",
      "like\n",
      "video\n",
      "vr\n",
      "good\n",
      "\n",
      "Topic  3\n",
      "game\n",
      "like\n",
      "world\n",
      "monster\n",
      "time\n",
      "\n",
      "\n",
      "The_Gaming_Brit_Show\n",
      "Topic  1\n",
      "announced\n",
      "review\n",
      "metroid\n",
      "wait\n",
      "thanks\n",
      "\n",
      "Topic  2\n",
      "dmc\n",
      "announced\n",
      "dante\n",
      "devil\n",
      "capcom\n",
      "\n",
      "Topic  3\n",
      "game\n",
      "like\n",
      "good\n",
      "really\n",
      "video\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for df in channels_obtained:\n",
    "    print(channel_names[count])\n",
    "    LDA_spelled_out(df, 3, 5)\n",
    "    print(\"\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF of Individual Videos\n",
    "group comments by bags fo words\n",
    "Sentament\n",
    "LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  1\n",
      "movie\n",
      "like\n",
      "really\n",
      "film\n",
      "horror\n",
      "watch\n",
      "think\n",
      "book\n",
      "time\n",
      "got\n",
      "Topic  2\n",
      "like\n",
      "video\n",
      "know\n",
      "nyx\n",
      "really\n",
      "loved\n",
      "day\n",
      "fuck\n",
      "time\n",
      "youtube\n",
      "Topic  3\n",
      "love\n",
      "nyx\n",
      "thanks\n",
      "na\n",
      "video\n",
      "great\n",
      "ghost\n",
      "movie\n",
      "demon\n",
      "gon\n",
      "Topic  4\n",
      "video\n",
      "love\n",
      "happy\n",
      "content\n",
      "great\n",
      "make\n",
      "look\n",
      "really\n",
      "amazing\n",
      "good\n",
      "Topic  5\n",
      "film\n",
      "man\n",
      "kid\n",
      "think\n",
      "scary\n",
      "better\n",
      "thing\n",
      "child\n",
      "make\n",
      "scene\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_components=5, n_jobs=1,\n",
       "             n_topics=None, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a dataframe \n",
    "#def LDA_spelled_out(df, num_topics = 3, num_words = 5):\n",
    "df = Nyx_Fears\n",
    "num_topics = 5\n",
    "num_words  = 10\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=num_topics)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cvec.fit(df['text'])\n",
    "text = cvec.transform(df['text'])\n",
    "lda.fit(text)\n",
    "for ix, topic in enumerate(lda.components_):\n",
    "    print('Topic ', ix + 1)\n",
    "    top_words = [cvec.get_feature_names()[i] for i in lda.components_[ix].argsort()[:-num_words - 1:-1]]\n",
    "    print('\\n'.join(top_words))\n",
    "    print('\\n')\n",
    "\n",
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21450505,  0.20041187,  0.20243854, ...,  0.20405071,\n",
       "         8.40743823,  0.20798659],\n",
       "       [ 0.20618235,  0.20184339,  2.58173108, ...,  0.41315623,\n",
       "         0.20219677,  0.20141358],\n",
       "       [ 0.20672888,  0.20042074,  0.20131888, ..., 17.4976868 ,\n",
       "         0.20139033,  0.20238979],\n",
       "       [ 2.84215885,  2.57312669,  0.20663176, ...,  0.20075433,\n",
       "         0.20120673,  0.20000552],\n",
       "       [ 0.20867792,  0.20085891,  0.20023359, ...,  0.20454549,\n",
       "         0.20162614,  1.97738498]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5145, 1773, 5598, ..., 3185, 3489, 2149],\n",
       "       [5451,  536, 1518, ..., 2609, 3424, 6162],\n",
       "       [ 376,  610, 3011, ..., 5721, 3894, 3424],\n",
       "       [ 610, 3678, 5349, ..., 3214, 6162, 3340],\n",
       "       [4054,  419, 1858, ..., 4589, 3340, 3727]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.argsort()[:-num_words - 1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>published_time</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>is_public</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "      <th>video_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>this is amazing!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-08-20T16:59:21.000Z</td>\n",
       "      <td>Holographic Marlon Brando</td>\n",
       "      <td>UChlhpJZ3FsfMsAKHLA96anQ</td>\n",
       "      <td>veyfNvN-Dv8</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugwt4ZgP_2Xjw_wigyp4AaABAg</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>The Meridian (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Violin play is unreal!!! An amazing additi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-28T04:30:43.000Z</td>\n",
       "      <td>Derek Misko</td>\n",
       "      <td>UCzuVPS84cZO2y-HRaEq2EVg</td>\n",
       "      <td>vcJgTzDBXko</td>\n",
       "      <td>True</td>\n",
       "      <td>UgxhvGBa-KzZ3D6opnp4AaABAg</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>Somebody I Used To Know (viola, guitar, voice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WOW!! :D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-02T18:17:55.000Z</td>\n",
       "      <td>xjoshx18</td>\n",
       "      <td>UCZ1bFfn6YWpsBcDwrLsGFhg</td>\n",
       "      <td>vcJgTzDBXko</td>\n",
       "      <td>True</td>\n",
       "      <td>UgggZ_zo5cSqE3gCoAEC</td>\n",
       "      <td>0.502083</td>\n",
       "      <td>Somebody I Used To Know (viola, guitar, voice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>did u guys use sheet music</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-02T00:31:52.000Z</td>\n",
       "      <td>Tiffany Artavia</td>\n",
       "      <td>UCIi2G8Eyy27b0bj7MonFoPA</td>\n",
       "      <td>vcJgTzDBXko</td>\n",
       "      <td>True</td>\n",
       "      <td>UghlKxBqyawUAngCoAEC</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Somebody I Used To Know (viola, guitar, voice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cool! works well in this arrangement :)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-13T15:44:39.000Z</td>\n",
       "      <td>Marc v/d Meulen</td>\n",
       "      <td>UCzzvUuTkl3NhEmmU83ndBlg</td>\n",
       "      <td>vcJgTzDBXko</td>\n",
       "      <td>True</td>\n",
       "      <td>UggB60hOXsHX7ngCoAEC</td>\n",
       "      <td>0.446875</td>\n",
       "      <td>Somebody I Used To Know (viola, guitar, voice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Great cover. What Model Viola is that?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-17T01:23:56.000Z</td>\n",
       "      <td>Shannon nonnahs</td>\n",
       "      <td>UCQK6M8EfTX5FPaHmAyI8vrA</td>\n",
       "      <td>vcJgTzDBXko</td>\n",
       "      <td>True</td>\n",
       "      <td>UgwqgRIaKyzyYAa9XZ54AaABAg</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>Somebody I Used To Know (viola, guitar, voice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>You can sing! Sing! This is great.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-17T14:45:38.000Z</td>\n",
       "      <td>alittlebitoffiddle</td>\n",
       "      <td>UCyJ6ndsDGDtVtnsov_iWsow</td>\n",
       "      <td>vcJgTzDBXko</td>\n",
       "      <td>True</td>\n",
       "      <td>UgyAks08mN0be1AMted4AaABAg</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>Somebody I Used To Know (viola, guitar, voice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>It's a 1974 Rudolf Buchner from West-Germany. :)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-17T20:00:02.000Z</td>\n",
       "      <td>Allison Edwards</td>\n",
       "      <td>UC1fpQ2FU54XfOFr-dqaWV3A</td>\n",
       "      <td>vcJgTzDBXko</td>\n",
       "      <td>True</td>\n",
       "      <td>UgxjjdEMM9Coo2SCeD54AaABAg</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>Somebody I Used To Know (viola, guitar, voice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>My friend and I are trying to find viola and v...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-11-12T23:37:29.000Z</td>\n",
       "      <td>Hazel Grey</td>\n",
       "      <td>UCRJg9cYJB-Io7EKDMnX3Kng</td>\n",
       "      <td>vcJgTzDBXko</td>\n",
       "      <td>True</td>\n",
       "      <td>UgjIfG47Eh7diXgCoAEC</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>Somebody I Used To Know (viola, guitar, voice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VIOLA FOREVER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-07-30T22:55:23.000Z</td>\n",
       "      <td>Out of Boredom</td>\n",
       "      <td>UCvcYkyasZhmx9qkkytln0Hw</td>\n",
       "      <td>oeTIb49Pgm0</td>\n",
       "      <td>True</td>\n",
       "      <td>UggVUwDBbGdkTngCoAEC</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Cough Syrup (acoustic cover)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I want to learn how to play it on the viola! D...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-05T04:26:45.000Z</td>\n",
       "      <td>Tikihead</td>\n",
       "      <td>UCqLaP8ohRF07ofiXxK0v0iA</td>\n",
       "      <td>oeTIb49Pgm0</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugi-aATWF6bF6ngCoAEC</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Cough Syrup (acoustic cover)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>violin why?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-05-11T16:41:55.000Z</td>\n",
       "      <td>burning charcoal</td>\n",
       "      <td>UCHI_gsjK8T_NZPk7MGAetYg</td>\n",
       "      <td>flSTkbgISAw</td>\n",
       "      <td>True</td>\n",
       "      <td>UgghLghn9j1zHXgCoAEC</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Never Too Late by Three Days Grace (acoustic c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>very nice, and always nice to see hot girls pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-07-24T10:43:55.000Z</td>\n",
       "      <td>siennasniper</td>\n",
       "      <td>UCdS04e-QAr7wmiXuGtVObMQ</td>\n",
       "      <td>flSTkbgISAw</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugy-feGw-f9FOg8F8O54AaABAg</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>Never Too Late by Three Days Grace (acoustic c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>So lazy :-[</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-16T21:09:09.000Z</td>\n",
       "      <td>SPOTxZAHRAN</td>\n",
       "      <td>UCK681WSNsOJQWfTILzJ1QaQ</td>\n",
       "      <td>flSTkbgISAw</td>\n",
       "      <td>True</td>\n",
       "      <td>UgwAKm4SzzlPs9i533V4AaABAg</td>\n",
       "      <td>-0.216667</td>\n",
       "      <td>Never Too Late by Three Days Grace (acoustic c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>It's like getting a 5 star chef to work at Mac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-21T23:19:40.000Z</td>\n",
       "      <td>clancy6969</td>\n",
       "      <td>UCS5BI376y2xQt_E10rqkeJQ</td>\n",
       "      <td>flSTkbgISAw</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugx1YgPDWX7y-k9HSGx4AaABAg</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Never Too Late by Three Days Grace (acoustic c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beautiful</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-18T02:37:06.000Z</td>\n",
       "      <td>William Allen</td>\n",
       "      <td>UCTcjdWf13yWpH_pKuno7r4w</td>\n",
       "      <td>QOD57KWArzM</td>\n",
       "      <td>True</td>\n",
       "      <td>UgiLY1SR0On4U3gCoAEC</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Acoustics, man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Awesome! Hi to Sean, tell him to \"phone home\" ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-23T06:33:03.000Z</td>\n",
       "      <td>David Silva</td>\n",
       "      <td>UCm2YIhZ9dtft3Xp1dV8rEig</td>\n",
       "      <td>QOD57KWArzM</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugyg1u2Ozp1XPDFJ78Z4AaABAg</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>Acoustics, man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beautiful cover. I love the peaceful soud of t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-30T14:20:03.000Z</td>\n",
       "      <td>Geovanni Castillo</td>\n",
       "      <td>UC0Z6kjxcA6886Kf0nH-d7JA</td>\n",
       "      <td>PT-0fWqQe2w</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugw6y-iZMY1MDf2S1dt4AaABAg</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>Big Jet Plane (viola guitar voice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You guys have nice chemistry, you should keep ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-07T02:29:04.000Z</td>\n",
       "      <td>Joshua Dreams</td>\n",
       "      <td>UC4oDIUzhY_Cbkb4D2K4npmA</td>\n",
       "      <td>OIS4h-zqHFo</td>\n",
       "      <td>True</td>\n",
       "      <td>UgiclKMRnGzksHgCoAEC</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>Oh Comely by Neutral Milk Hotel (guitar violin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>alison check out some music on my channel and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-23T18:15:49.000Z</td>\n",
       "      <td>Nghia Tran</td>\n",
       "      <td>UCXxhTcUu9Y_-tbnZYPELM6A</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugw95eXk9DWNomZ70Ip4AaABAg</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Discussion Comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Allison , i loved this version of big jet plan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-02T14:26:49.000Z</td>\n",
       "      <td>Tamara Collombo</td>\n",
       "      <td>UCSJ5DmGga8tL1SQGkYEwLiw</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>UghzgIR-MO4GNHgCoAEC</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Discussion Comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>hey :) thanks a bunch for subscribing!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-06-19T02:48:56.000Z</td>\n",
       "      <td>ticaadilly</td>\n",
       "      <td>UCj15syuxtbDKN40wqSK-G4w</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>UgxayHR1BpfvDZa01ON4AaABAg</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>Discussion Comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VIOLA POWER!!!!! i play viola but i suck</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-09-19T03:31:02.000Z</td>\n",
       "      <td>Lex Olaes</td>\n",
       "      <td>UCZdjZ-sGuirYGCczuNFv8uw</td>\n",
       "      <td>MgP_6GipDCU</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugxu9OJJoE0xBKamrEZ4AaABAg</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Secrets by OneRepublic (viola, guitar, two voi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What a nice tune here. I adore your musiciansh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-22T11:35:51.000Z</td>\n",
       "      <td>Ashton Haze</td>\n",
       "      <td>UCAhdfSEtS7qZtaCrpMc_cHw</td>\n",
       "      <td>LbFhwWeysDI</td>\n",
       "      <td>True</td>\n",
       "      <td>UgwIBcdJVHMnwKQIGDZ4AaABAg</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>Come Home by OneRepublic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>you guys did awesome! you rocked it! :)\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-20T03:24:16.000Z</td>\n",
       "      <td>violindork11</td>\n",
       "      <td>UCTqo9ni1LHxCbjNT1S7oFIw</td>\n",
       "      <td>KeOtZghc194</td>\n",
       "      <td>True</td>\n",
       "      <td>UgzoxJ2WnF71vgaygEV4AaABAg</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>Beethoven Serenade in D major, Op. 25 Trio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Oh okay thank you anyway c:!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-19T16:12:32.000Z</td>\n",
       "      <td>NeonDino23</td>\n",
       "      <td>UCO8T1GrmUvEfU6Cu88R-Ksg</td>\n",
       "      <td>JqmWhozWOhw</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugy42nZvUQ7PytIWHn94AaABAg</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>Soul Meets Body (viola acoustic cover)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Unfortunately I played by ear and improvised. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-16T14:27:15.000Z</td>\n",
       "      <td>Allison Edwards</td>\n",
       "      <td>UC1fpQ2FU54XfOFr-dqaWV3A</td>\n",
       "      <td>JqmWhozWOhw</td>\n",
       "      <td>True</td>\n",
       "      <td>Ugy93OktKZ1pfVg3FoJ4AaABAg</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>Soul Meets Body (viola acoustic cover)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Viola Sheet music Please c:!!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-09T00:38:32.000Z</td>\n",
       "      <td>NeonDino23</td>\n",
       "      <td>UCO8T1GrmUvEfU6Cu88R-Ksg</td>\n",
       "      <td>JqmWhozWOhw</td>\n",
       "      <td>True</td>\n",
       "      <td>UgyOAWtBjChq1vX1pv94AaABAg</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Soul Meets Body (viola acoustic cover)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi there,\\n My name is Gianna and I am 13 year...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-10-24T19:14:03.000Z</td>\n",
       "      <td>brenda d</td>\n",
       "      <td>UCgMX-2kKmlIuiMxDpBYUeSA</td>\n",
       "      <td>4j5d06YbU1o</td>\n",
       "      <td>True</td>\n",
       "      <td>UgwwtuzUR5fIfE0b9554AaABAg</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Simple Man by Lynyrd Skynyrd (violin, guitar, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sick!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-11T22:21:31.000Z</td>\n",
       "      <td>Aidan Ip</td>\n",
       "      <td>UCqKwxE2DRVglvloeqRh-HCA</td>\n",
       "      <td>3OwnPr_5JJA</td>\n",
       "      <td>True</td>\n",
       "      <td>UgxgJhu_XiIa6QZ5Bjd4AaABAg</td>\n",
       "      <td>-0.271429</td>\n",
       "      <td>She Will Be Loved By Maroon 5 (viola, guitar, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>thanks! :)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-08-22T23:12:06.000Z</td>\n",
       "      <td>Allison Edwards</td>\n",
       "      <td>UC1fpQ2FU54XfOFr-dqaWV3A</td>\n",
       "      <td>-WNfFu4AgxE</td>\n",
       "      <td>True</td>\n",
       "      <td>UgzpX_Tzcitv-yPJTlR4AaABAg</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>White Flag by Dido (violin, guitar, voice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Great cover!!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-08-21T17:22:29.000Z</td>\n",
       "      <td>Santiago González</td>\n",
       "      <td>UCADrDa-kjeY71p8Jz3QfLIA</td>\n",
       "      <td>-WNfFu4AgxE</td>\n",
       "      <td>True</td>\n",
       "      <td>UgzPD2b99pJE_spYVzl4AaABAg</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>White Flag by Dido (violin, guitar, voice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-08-14T02:06:16.000Z</td>\n",
       "      <td>WombatC</td>\n",
       "      <td>UC68p4wszWwyT7Bmpxnz90yg</td>\n",
       "      <td>-WNfFu4AgxE</td>\n",
       "      <td>True</td>\n",
       "      <td>UghZfFueMbGi3HgCoAEC</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>White Flag by Dido (violin, guitar, voice)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  likes  replies  \\\n",
       "27                                 this is amazing!!!      0        0   \n",
       "18  The Violin play is unreal!!! An amazing additi...      0        0   \n",
       "10                                           WOW!! :D      0        0   \n",
       "2                          did u guys use sheet music      0        0   \n",
       "3             Cool! works well in this arrangement :)      0        0   \n",
       "30             Great cover. What Model Viola is that?      0        0   \n",
       "29                 You can sing! Sing! This is great.      0        0   \n",
       "28   It's a 1974 Rudolf Buchner from West-Germany. :)      0        0   \n",
       "11  My friend and I are trying to find viola and v...      0        0   \n",
       "8                                       VIOLA FOREVER      0        0   \n",
       "7   I want to learn how to play it on the viola! D...      0        0   \n",
       "9                                         violin why?      0        0   \n",
       "17  very nice, and always nice to see hot girls pl...      0        0   \n",
       "13                                        So lazy :-[      0        0   \n",
       "16  It's like getting a 5 star chef to work at Mac...      0        0   \n",
       "4                                           Beautiful      0        0   \n",
       "15  Awesome! Hi to Sean, tell him to \"phone home\" ...      0        0   \n",
       "0   Beautiful cover. I love the peaceful soud of t...      0        0   \n",
       "6   You guys have nice chemistry, you should keep ...      0        0   \n",
       "19  alison check out some music on my channel and ...      0        0   \n",
       "14  Allison , i loved this version of big jet plan...      0        0   \n",
       "32             hey :) thanks a bunch for subscribing!      0        0   \n",
       "24           VIOLA POWER!!!!! i play viola but i suck      0        0   \n",
       "12  What a nice tune here. I adore your musiciansh...      0        0   \n",
       "20          you guys did awesome! you rocked it! :)\\n      0        0   \n",
       "21                       Oh okay thank you anyway c:!      0        0   \n",
       "22  Unfortunately I played by ear and improvised. ...      0        0   \n",
       "23                      Viola Sheet music Please c:!!      0        0   \n",
       "1   Hi there,\\n My name is Gianna and I am 13 year...      0        2   \n",
       "31                                              sick!      0        0   \n",
       "25                                         thanks! :)      0        0   \n",
       "26                                      Great cover!!      0        0   \n",
       "5                                           I love it      0        0   \n",
       "\n",
       "              published_time                author_name  \\\n",
       "27  2012-08-20T16:59:21.000Z  Holographic Marlon Brando   \n",
       "18  2013-03-28T04:30:43.000Z                Derek Misko   \n",
       "10  2014-01-02T18:17:55.000Z                   xjoshx18   \n",
       "2   2016-12-02T00:31:52.000Z            Tiffany Artavia   \n",
       "3   2016-06-13T15:44:39.000Z            Marc v/d Meulen   \n",
       "30  2012-07-17T01:23:56.000Z            Shannon nonnahs   \n",
       "29  2012-07-17T14:45:38.000Z         alittlebitoffiddle   \n",
       "28  2012-07-17T20:00:02.000Z            Allison Edwards   \n",
       "11  2013-11-12T23:37:29.000Z                 Hazel Grey   \n",
       "8   2014-07-30T22:55:23.000Z             Out of Boredom   \n",
       "7   2015-01-05T04:26:45.000Z                   Tikihead   \n",
       "9   2014-05-11T16:41:55.000Z           burning charcoal   \n",
       "17  2013-07-24T10:43:55.000Z               siennasniper   \n",
       "13  2013-10-16T21:09:09.000Z                SPOTxZAHRAN   \n",
       "16  2013-08-21T23:19:40.000Z                 clancy6969   \n",
       "4   2015-12-18T02:37:06.000Z              William Allen   \n",
       "15  2013-08-23T06:33:03.000Z                David Silva   \n",
       "0   2018-04-30T14:20:03.000Z          Geovanni Castillo   \n",
       "6   2015-04-07T02:29:04.000Z              Joshua Dreams   \n",
       "19  2012-10-23T18:15:49.000Z                 Nghia Tran   \n",
       "14  2013-10-02T14:26:49.000Z            Tamara Collombo   \n",
       "32  2012-06-19T02:48:56.000Z                 ticaadilly   \n",
       "24  2012-09-19T03:31:02.000Z                  Lex Olaes   \n",
       "12  2013-10-22T11:35:51.000Z                Ashton Haze   \n",
       "20  2012-10-20T03:24:16.000Z               violindork11   \n",
       "21  2012-10-19T16:12:32.000Z                 NeonDino23   \n",
       "22  2012-10-16T14:27:15.000Z            Allison Edwards   \n",
       "23  2012-10-09T00:38:32.000Z                 NeonDino23   \n",
       "1   2017-10-24T19:14:03.000Z                   brenda d   \n",
       "31  2012-07-11T22:21:31.000Z                   Aidan Ip   \n",
       "25  2012-08-22T23:12:06.000Z            Allison Edwards   \n",
       "26  2012-08-21T17:22:29.000Z          Santiago González   \n",
       "5   2015-08-14T02:06:16.000Z                    WombatC   \n",
       "\n",
       "                   author_id     video_id  is_public  \\\n",
       "27  UChlhpJZ3FsfMsAKHLA96anQ  veyfNvN-Dv8       True   \n",
       "18  UCzuVPS84cZO2y-HRaEq2EVg  vcJgTzDBXko       True   \n",
       "10  UCZ1bFfn6YWpsBcDwrLsGFhg  vcJgTzDBXko       True   \n",
       "2   UCIi2G8Eyy27b0bj7MonFoPA  vcJgTzDBXko       True   \n",
       "3   UCzzvUuTkl3NhEmmU83ndBlg  vcJgTzDBXko       True   \n",
       "30  UCQK6M8EfTX5FPaHmAyI8vrA  vcJgTzDBXko       True   \n",
       "29  UCyJ6ndsDGDtVtnsov_iWsow  vcJgTzDBXko       True   \n",
       "28  UC1fpQ2FU54XfOFr-dqaWV3A  vcJgTzDBXko       True   \n",
       "11  UCRJg9cYJB-Io7EKDMnX3Kng  vcJgTzDBXko       True   \n",
       "8   UCvcYkyasZhmx9qkkytln0Hw  oeTIb49Pgm0       True   \n",
       "7   UCqLaP8ohRF07ofiXxK0v0iA  oeTIb49Pgm0       True   \n",
       "9   UCHI_gsjK8T_NZPk7MGAetYg  flSTkbgISAw       True   \n",
       "17  UCdS04e-QAr7wmiXuGtVObMQ  flSTkbgISAw       True   \n",
       "13  UCK681WSNsOJQWfTILzJ1QaQ  flSTkbgISAw       True   \n",
       "16  UCS5BI376y2xQt_E10rqkeJQ  flSTkbgISAw       True   \n",
       "4   UCTcjdWf13yWpH_pKuno7r4w  QOD57KWArzM       True   \n",
       "15  UCm2YIhZ9dtft3Xp1dV8rEig  QOD57KWArzM       True   \n",
       "0   UC0Z6kjxcA6886Kf0nH-d7JA  PT-0fWqQe2w       True   \n",
       "6   UC4oDIUzhY_Cbkb4D2K4npmA  OIS4h-zqHFo       True   \n",
       "19  UCXxhTcUu9Y_-tbnZYPELM6A         None       True   \n",
       "14  UCSJ5DmGga8tL1SQGkYEwLiw         None       True   \n",
       "32  UCj15syuxtbDKN40wqSK-G4w         None       True   \n",
       "24  UCZdjZ-sGuirYGCczuNFv8uw  MgP_6GipDCU       True   \n",
       "12  UCAhdfSEtS7qZtaCrpMc_cHw  LbFhwWeysDI       True   \n",
       "20  UCTqo9ni1LHxCbjNT1S7oFIw  KeOtZghc194       True   \n",
       "21  UCO8T1GrmUvEfU6Cu88R-Ksg  JqmWhozWOhw       True   \n",
       "22  UC1fpQ2FU54XfOFr-dqaWV3A  JqmWhozWOhw       True   \n",
       "23  UCO8T1GrmUvEfU6Cu88R-Ksg  JqmWhozWOhw       True   \n",
       "1   UCgMX-2kKmlIuiMxDpBYUeSA  4j5d06YbU1o       True   \n",
       "31  UCqKwxE2DRVglvloeqRh-HCA  3OwnPr_5JJA       True   \n",
       "25  UC1fpQ2FU54XfOFr-dqaWV3A  -WNfFu4AgxE       True   \n",
       "26  UCADrDa-kjeY71p8Jz3QfLIA  -WNfFu4AgxE       True   \n",
       "5   UC68p4wszWwyT7Bmpxnz90yg  -WNfFu4AgxE       True   \n",
       "\n",
       "                    comment_id  sentiment_textblob  \\\n",
       "27  Ugwt4ZgP_2Xjw_wigyp4AaABAg            0.675000   \n",
       "18  UgxhvGBa-KzZ3D6opnp4AaABAg            0.475000   \n",
       "10        UgggZ_zo5cSqE3gCoAEC            0.502083   \n",
       "2         UghlKxBqyawUAngCoAEC            0.350000   \n",
       "3         UggB60hOXsHX7ngCoAEC            0.446875   \n",
       "30  UgwqgRIaKyzyYAa9XZ54AaABAg            0.575000   \n",
       "29  UgyAks08mN0be1AMted4AaABAg            0.575000   \n",
       "28  UgxjjdEMM9Coo2SCeD54AaABAg            0.425000   \n",
       "11        UgjIfG47Eh7diXgCoAEC            0.150000   \n",
       "8         UggVUwDBbGdkTngCoAEC            0.350000   \n",
       "7         Ugi-aATWF6bF6ngCoAEC            0.350000   \n",
       "9         UgghLghn9j1zHXgCoAEC            0.350000   \n",
       "17  Ugy-feGw-f9FOg8F8O54AaABAg            0.495000   \n",
       "13  UgwAKm4SzzlPs9i533V4AaABAg           -0.216667   \n",
       "16  Ugx1YgPDWX7y-k9HSGx4AaABAg            0.350000   \n",
       "4         UgiLY1SR0On4U3gCoAEC            0.600000   \n",
       "15  Ugyg1u2Ozp1XPDFJ78Z4AaABAg            0.675000   \n",
       "0   Ugw6y-iZMY1MDf2S1dt4AaABAg            0.487500   \n",
       "6         UgiclKMRnGzksHgCoAEC            0.475000   \n",
       "19  Ugw95eXk9DWNomZ70Ip4AaABAg            0.350000   \n",
       "14        UghzgIR-MO4GNHgCoAEC            0.350000   \n",
       "32  UgxayHR1BpfvDZa01ON4AaABAg            0.366667   \n",
       "24  Ugxu9OJJoE0xBKamrEZ4AaABAg            0.350000   \n",
       "12  UgwIBcdJVHMnwKQIGDZ4AaABAg            0.475000   \n",
       "20  UgzoxJ2WnF71vgaygEV4AaABAg            0.616667   \n",
       "21  Ugy42nZvUQ7PytIWHn94AaABAg            0.487500   \n",
       "22  Ugy93OktKZ1pfVg3FoJ4AaABAg           -0.075000   \n",
       "23  UgyOAWtBjChq1vX1pv94AaABAg            0.350000   \n",
       "1   UgwwtuzUR5fIfE0b9554AaABAg            0.350000   \n",
       "31  UgxgJhu_XiIa6QZ5Bjd4AaABAg           -0.271429   \n",
       "25  UgzpX_Tzcitv-yPJTlR4AaABAg            0.366667   \n",
       "26  UgzPD2b99pJE_spYVzl4AaABAg            0.675000   \n",
       "5         UghZfFueMbGi3HgCoAEC            0.425000   \n",
       "\n",
       "                                          video_title  \n",
       "27                            The Meridian (original)  \n",
       "18     Somebody I Used To Know (viola, guitar, voice)  \n",
       "10     Somebody I Used To Know (viola, guitar, voice)  \n",
       "2      Somebody I Used To Know (viola, guitar, voice)  \n",
       "3      Somebody I Used To Know (viola, guitar, voice)  \n",
       "30     Somebody I Used To Know (viola, guitar, voice)  \n",
       "29     Somebody I Used To Know (viola, guitar, voice)  \n",
       "28     Somebody I Used To Know (viola, guitar, voice)  \n",
       "11     Somebody I Used To Know (viola, guitar, voice)  \n",
       "8                        Cough Syrup (acoustic cover)  \n",
       "7                        Cough Syrup (acoustic cover)  \n",
       "9   Never Too Late by Three Days Grace (acoustic c...  \n",
       "17  Never Too Late by Three Days Grace (acoustic c...  \n",
       "13  Never Too Late by Three Days Grace (acoustic c...  \n",
       "16  Never Too Late by Three Days Grace (acoustic c...  \n",
       "4                                      Acoustics, man  \n",
       "15                                     Acoustics, man  \n",
       "0                  Big Jet Plane (viola guitar voice)  \n",
       "6   Oh Comely by Neutral Milk Hotel (guitar violin...  \n",
       "19                                 Discussion Comment  \n",
       "14                                 Discussion Comment  \n",
       "32                                 Discussion Comment  \n",
       "24  Secrets by OneRepublic (viola, guitar, two voi...  \n",
       "12                           Come Home by OneRepublic  \n",
       "20         Beethoven Serenade in D major, Op. 25 Trio  \n",
       "21             Soul Meets Body (viola acoustic cover)  \n",
       "22             Soul Meets Body (viola acoustic cover)  \n",
       "23             Soul Meets Body (viola acoustic cover)  \n",
       "1   Simple Man by Lynyrd Skynyrd (violin, guitar, ...  \n",
       "31  She Will Be Loved By Maroon 5 (viola, guitar, ...  \n",
       "25         White Flag by Dido (violin, guitar, voice)  \n",
       "26         White Flag by Dido (violin, guitar, voice)  \n",
       "5          White Flag by Dido (violin, guitar, voice)  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Allison.sort_values(by = 'video_id', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>published_time</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_id</th>\n",
       "      <th>is_public</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "      <th>video_title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">-WNfFu4AgxE</th>\n",
       "      <th>UghZfFueMbGi3HgCoAEC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UgzPD2b99pJE_spYVzl4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UgzpX_Tzcitv-yPJTlR4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3OwnPr_5JJA</th>\n",
       "      <th>UgxgJhu_XiIa6QZ5Bjd4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4j5d06YbU1o</th>\n",
       "      <th>UgwwtuzUR5fIfE0b9554AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">JqmWhozWOhw</th>\n",
       "      <th>Ugy42nZvUQ7PytIWHn94AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ugy93OktKZ1pfVg3FoJ4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UgyOAWtBjChq1vX1pv94AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeOtZghc194</th>\n",
       "      <th>UgzoxJ2WnF71vgaygEV4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LbFhwWeysDI</th>\n",
       "      <th>UgwIBcdJVHMnwKQIGDZ4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MgP_6GipDCU</th>\n",
       "      <th>Ugxu9OJJoE0xBKamrEZ4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">None</th>\n",
       "      <th>UghzgIR-MO4GNHgCoAEC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ugw95eXk9DWNomZ70Ip4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UgxayHR1BpfvDZa01ON4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OIS4h-zqHFo</th>\n",
       "      <th>UgiclKMRnGzksHgCoAEC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-0fWqQe2w</th>\n",
       "      <th>Ugw6y-iZMY1MDf2S1dt4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">QOD57KWArzM</th>\n",
       "      <th>UgiLY1SR0On4U3gCoAEC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ugyg1u2Ozp1XPDFJ78Z4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">flSTkbgISAw</th>\n",
       "      <th>UgghLghn9j1zHXgCoAEC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UgwAKm4SzzlPs9i533V4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ugx1YgPDWX7y-k9HSGx4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ugy-feGw-f9FOg8F8O54AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">oeTIb49Pgm0</th>\n",
       "      <th>UggVUwDBbGdkTngCoAEC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ugi-aATWF6bF6ngCoAEC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">vcJgTzDBXko</th>\n",
       "      <th>UggB60hOXsHX7ngCoAEC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UgggZ_zo5cSqE3gCoAEC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UghlKxBqyawUAngCoAEC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UgjIfG47Eh7diXgCoAEC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UgwqgRIaKyzyYAa9XZ54AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UgxhvGBa-KzZ3D6opnp4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UgxjjdEMM9Coo2SCeD54AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UgyAks08mN0be1AMted4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veyfNvN-Dv8</th>\n",
       "      <th>Ugwt4ZgP_2Xjw_wigyp4AaABAg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text  likes  replies  published_time  \\\n",
       "video_id    comment_id                                                         \n",
       "-WNfFu4AgxE UghZfFueMbGi3HgCoAEC           1      1        1               1   \n",
       "            UgzPD2b99pJE_spYVzl4AaABAg     1      1        1               1   \n",
       "            UgzpX_Tzcitv-yPJTlR4AaABAg     1      1        1               1   \n",
       "3OwnPr_5JJA UgxgJhu_XiIa6QZ5Bjd4AaABAg     1      1        1               1   \n",
       "4j5d06YbU1o UgwwtuzUR5fIfE0b9554AaABAg     1      1        1               1   \n",
       "JqmWhozWOhw Ugy42nZvUQ7PytIWHn94AaABAg     1      1        1               1   \n",
       "            Ugy93OktKZ1pfVg3FoJ4AaABAg     1      1        1               1   \n",
       "            UgyOAWtBjChq1vX1pv94AaABAg     1      1        1               1   \n",
       "KeOtZghc194 UgzoxJ2WnF71vgaygEV4AaABAg     1      1        1               1   \n",
       "LbFhwWeysDI UgwIBcdJVHMnwKQIGDZ4AaABAg     1      1        1               1   \n",
       "MgP_6GipDCU Ugxu9OJJoE0xBKamrEZ4AaABAg     1      1        1               1   \n",
       "None        UghzgIR-MO4GNHgCoAEC           1      1        1               1   \n",
       "            Ugw95eXk9DWNomZ70Ip4AaABAg     1      1        1               1   \n",
       "            UgxayHR1BpfvDZa01ON4AaABAg     1      1        1               1   \n",
       "OIS4h-zqHFo UgiclKMRnGzksHgCoAEC           1      1        1               1   \n",
       "PT-0fWqQe2w Ugw6y-iZMY1MDf2S1dt4AaABAg     1      1        1               1   \n",
       "QOD57KWArzM UgiLY1SR0On4U3gCoAEC           1      1        1               1   \n",
       "            Ugyg1u2Ozp1XPDFJ78Z4AaABAg     1      1        1               1   \n",
       "flSTkbgISAw UgghLghn9j1zHXgCoAEC           1      1        1               1   \n",
       "            UgwAKm4SzzlPs9i533V4AaABAg     1      1        1               1   \n",
       "            Ugx1YgPDWX7y-k9HSGx4AaABAg     1      1        1               1   \n",
       "            Ugy-feGw-f9FOg8F8O54AaABAg     1      1        1               1   \n",
       "oeTIb49Pgm0 UggVUwDBbGdkTngCoAEC           1      1        1               1   \n",
       "            Ugi-aATWF6bF6ngCoAEC           1      1        1               1   \n",
       "vcJgTzDBXko UggB60hOXsHX7ngCoAEC           1      1        1               1   \n",
       "            UgggZ_zo5cSqE3gCoAEC           1      1        1               1   \n",
       "            UghlKxBqyawUAngCoAEC           1      1        1               1   \n",
       "            UgjIfG47Eh7diXgCoAEC           1      1        1               1   \n",
       "            UgwqgRIaKyzyYAa9XZ54AaABAg     1      1        1               1   \n",
       "            UgxhvGBa-KzZ3D6opnp4AaABAg     1      1        1               1   \n",
       "            UgxjjdEMM9Coo2SCeD54AaABAg     1      1        1               1   \n",
       "            UgyAks08mN0be1AMted4AaABAg     1      1        1               1   \n",
       "veyfNvN-Dv8 Ugwt4ZgP_2Xjw_wigyp4AaABAg     1      1        1               1   \n",
       "\n",
       "                                        author_name  author_id  is_public  \\\n",
       "video_id    comment_id                                                      \n",
       "-WNfFu4AgxE UghZfFueMbGi3HgCoAEC                  1          1          1   \n",
       "            UgzPD2b99pJE_spYVzl4AaABAg            1          1          1   \n",
       "            UgzpX_Tzcitv-yPJTlR4AaABAg            1          1          1   \n",
       "3OwnPr_5JJA UgxgJhu_XiIa6QZ5Bjd4AaABAg            1          1          1   \n",
       "4j5d06YbU1o UgwwtuzUR5fIfE0b9554AaABAg            1          1          1   \n",
       "JqmWhozWOhw Ugy42nZvUQ7PytIWHn94AaABAg            1          1          1   \n",
       "            Ugy93OktKZ1pfVg3FoJ4AaABAg            1          1          1   \n",
       "            UgyOAWtBjChq1vX1pv94AaABAg            1          1          1   \n",
       "KeOtZghc194 UgzoxJ2WnF71vgaygEV4AaABAg            1          1          1   \n",
       "LbFhwWeysDI UgwIBcdJVHMnwKQIGDZ4AaABAg            1          1          1   \n",
       "MgP_6GipDCU Ugxu9OJJoE0xBKamrEZ4AaABAg            1          1          1   \n",
       "None        UghzgIR-MO4GNHgCoAEC                  1          1          1   \n",
       "            Ugw95eXk9DWNomZ70Ip4AaABAg            1          1          1   \n",
       "            UgxayHR1BpfvDZa01ON4AaABAg            1          1          1   \n",
       "OIS4h-zqHFo UgiclKMRnGzksHgCoAEC                  1          1          1   \n",
       "PT-0fWqQe2w Ugw6y-iZMY1MDf2S1dt4AaABAg            1          1          1   \n",
       "QOD57KWArzM UgiLY1SR0On4U3gCoAEC                  1          1          1   \n",
       "            Ugyg1u2Ozp1XPDFJ78Z4AaABAg            1          1          1   \n",
       "flSTkbgISAw UgghLghn9j1zHXgCoAEC                  1          1          1   \n",
       "            UgwAKm4SzzlPs9i533V4AaABAg            1          1          1   \n",
       "            Ugx1YgPDWX7y-k9HSGx4AaABAg            1          1          1   \n",
       "            Ugy-feGw-f9FOg8F8O54AaABAg            1          1          1   \n",
       "oeTIb49Pgm0 UggVUwDBbGdkTngCoAEC                  1          1          1   \n",
       "            Ugi-aATWF6bF6ngCoAEC                  1          1          1   \n",
       "vcJgTzDBXko UggB60hOXsHX7ngCoAEC                  1          1          1   \n",
       "            UgggZ_zo5cSqE3gCoAEC                  1          1          1   \n",
       "            UghlKxBqyawUAngCoAEC                  1          1          1   \n",
       "            UgjIfG47Eh7diXgCoAEC                  1          1          1   \n",
       "            UgwqgRIaKyzyYAa9XZ54AaABAg            1          1          1   \n",
       "            UgxhvGBa-KzZ3D6opnp4AaABAg            1          1          1   \n",
       "            UgxjjdEMM9Coo2SCeD54AaABAg            1          1          1   \n",
       "            UgyAks08mN0be1AMted4AaABAg            1          1          1   \n",
       "veyfNvN-Dv8 Ugwt4ZgP_2Xjw_wigyp4AaABAg            1          1          1   \n",
       "\n",
       "                                        sentiment_textblob  video_title  \n",
       "video_id    comment_id                                                   \n",
       "-WNfFu4AgxE UghZfFueMbGi3HgCoAEC                         1            1  \n",
       "            UgzPD2b99pJE_spYVzl4AaABAg                   1            1  \n",
       "            UgzpX_Tzcitv-yPJTlR4AaABAg                   1            1  \n",
       "3OwnPr_5JJA UgxgJhu_XiIa6QZ5Bjd4AaABAg                   1            1  \n",
       "4j5d06YbU1o UgwwtuzUR5fIfE0b9554AaABAg                   1            1  \n",
       "JqmWhozWOhw Ugy42nZvUQ7PytIWHn94AaABAg                   1            1  \n",
       "            Ugy93OktKZ1pfVg3FoJ4AaABAg                   1            1  \n",
       "            UgyOAWtBjChq1vX1pv94AaABAg                   1            1  \n",
       "KeOtZghc194 UgzoxJ2WnF71vgaygEV4AaABAg                   1            1  \n",
       "LbFhwWeysDI UgwIBcdJVHMnwKQIGDZ4AaABAg                   1            1  \n",
       "MgP_6GipDCU Ugxu9OJJoE0xBKamrEZ4AaABAg                   1            1  \n",
       "None        UghzgIR-MO4GNHgCoAEC                         1            1  \n",
       "            Ugw95eXk9DWNomZ70Ip4AaABAg                   1            1  \n",
       "            UgxayHR1BpfvDZa01ON4AaABAg                   1            1  \n",
       "OIS4h-zqHFo UgiclKMRnGzksHgCoAEC                         1            1  \n",
       "PT-0fWqQe2w Ugw6y-iZMY1MDf2S1dt4AaABAg                   1            1  \n",
       "QOD57KWArzM UgiLY1SR0On4U3gCoAEC                         1            1  \n",
       "            Ugyg1u2Ozp1XPDFJ78Z4AaABAg                   1            1  \n",
       "flSTkbgISAw UgghLghn9j1zHXgCoAEC                         1            1  \n",
       "            UgwAKm4SzzlPs9i533V4AaABAg                   1            1  \n",
       "            Ugx1YgPDWX7y-k9HSGx4AaABAg                   1            1  \n",
       "            Ugy-feGw-f9FOg8F8O54AaABAg                   1            1  \n",
       "oeTIb49Pgm0 UggVUwDBbGdkTngCoAEC                         1            1  \n",
       "            Ugi-aATWF6bF6ngCoAEC                         1            1  \n",
       "vcJgTzDBXko UggB60hOXsHX7ngCoAEC                         1            1  \n",
       "            UgggZ_zo5cSqE3gCoAEC                         1            1  \n",
       "            UghlKxBqyawUAngCoAEC                         1            1  \n",
       "            UgjIfG47Eh7diXgCoAEC                         1            1  \n",
       "            UgwqgRIaKyzyYAa9XZ54AaABAg                   1            1  \n",
       "            UgxhvGBa-KzZ3D6opnp4AaABAg                   1            1  \n",
       "            UgxjjdEMM9Coo2SCeD54AaABAg                   1            1  \n",
       "            UgyAks08mN0be1AMted4AaABAg                   1            1  \n",
       "veyfNvN-Dv8 Ugwt4ZgP_2Xjw_wigyp4AaABAg                   1            1  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Allison.groupby(['video_id','comment_id']).count()      # Obtain number of comments per video\n",
    "#, 1, as_index=True,level=None).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-25f38dd890ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcvec_Allison\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "cvec_Allison.groupby().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-adabb08d21e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAllison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'count'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mAllison\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m\"video_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "Allison({'count' : Allison.groupby( [ \"video_id\"] ).size()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Labority Things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting to sentimentize Each individual Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-WNfFu4AgxE',\n",
       " '3OwnPr_5JJA',\n",
       " '4j5d06YbU1o',\n",
       " 'JqmWhozWOhw',\n",
       " 'KeOtZghc194',\n",
       " 'LbFhwWeysDI',\n",
       " 'MgP_6GipDCU',\n",
       " 'None',\n",
       " 'OIS4h-zqHFo',\n",
       " 'PT-0fWqQe2w',\n",
       " 'QOD57KWArzM',\n",
       " 'flSTkbgISAw',\n",
       " 'oeTIb49Pgm0',\n",
       " 'vcJgTzDBXko',\n",
       " 'veyfNvN-Dv8'}"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Allison['video_id'])\n",
    "# Step 1 Group each by video\n",
    "# Bons 1 Obtain name of video\n",
    "# Step 2 Sentimentize rows by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mask = Allison['video_id'].any() == '3OwnPr_5JJA'\n",
    "#Allison[mask]\n",
    "#df.loc[df['column_name'] == some_value]\n",
    "Allison.filter(items = ['4j5d06YbU1o'])#loc[df['video_id'] == 'None']\n",
    "#df.loc[df['A'] == 'foo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = The_Gaming_Brit_Show.isnull().any(axis = 1) == True\n",
    "The_Gaming_Brit_Show[mask]['text']#.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment per each individual video\n",
    "def sentiment_of_videos(df):\n",
    "    videos = set(df['video_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41179036458333335"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Allison['sentiment_textblob'].drop(31).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4610418855042018"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentamentize(Allison['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliens_Guide\n",
      "\n",
      "Y_0sVITj9K8    288\n",
      "sneU_11ncq4    156\n",
      "bf8-zUiw80I    124\n",
      "_LyN2vsyARQ     68\n",
      "9_IEcyhS1DI     28\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Allison\n",
      "\n",
      "vcJgTzDBXko    8\n",
      "flSTkbgISAw    4\n",
      "JqmWhozWOhw    3\n",
      "None           3\n",
      "-WNfFu4AgxE    3\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Ant_Dude\n",
      "\n",
      "mfX_RDgAx08    1164\n",
      "zjahtcvQH24     830\n",
      "hKIgQKM4ieM     779\n",
      "VoVAT2l-6TM     636\n",
      "mS8Xu2ZJpL4     633\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Black_Pilled\n",
      "\n",
      "vwFshwxECq0    1505\n",
      "q8IlXA4ArPg    1266\n",
      "1-kdygA5U_k    1177\n",
      "fukC0KdQWfE    1018\n",
      "HwbzF9tKSd8    1017\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "CinemaSins\n",
      "\n",
      "tNZSFJ3iE8g    2479\n",
      "UFiJB9mJJc0    1244\n",
      "9QM7X6JjlCo     754\n",
      "cRWazG4_egE     295\n",
      "plc2c84pM5I     232\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "CinemaWins\n",
      "\n",
      "UImXWiDFAoE    1773\n",
      "nPsWI6c5ayI    1370\n",
      "tK4-NV1kYQU    1354\n",
      "b7evmxZyz_M    1047\n",
      "ydHEGhQghPY     808\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "ContraPoints\n",
      "\n",
      "fD2briZ6fB0    8927\n",
      "Sx4BVGPkdzk    5039\n",
      "4LqZdkkBDas    5038\n",
      "z1afqR5QkDM    3741\n",
      "hyaftqCORT4    3379\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Everyman_HYBRID\n",
      "\n",
      "xHHg7VExr9I    1361\n",
      "oIW9Oo53ZYk    1091\n",
      "c3Ccq2ghxjQ    1076\n",
      "WBN81hnxh8g    1059\n",
      "jY6yH6Odmh4     899\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Hi_Im_Mary_Mary\n",
      "\n",
      "MlijLvD2Ocg    1298\n",
      "JukFMYGI6Ko     588\n",
      "Pn3oNkExNlY     587\n",
      "ZPOcSKaKfKA     307\n",
      "None              1\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "LaRon_Readus\n",
      "\n",
      "_eKfyBk1WBE    157\n",
      "nlCpfqp1Be0    110\n",
      "QpEwpzIpEr8     84\n",
      "59dYHupLs-Q     75\n",
      "oUURMZiMVcA     73\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Lindsay_Ellis\n",
      "\n",
      "vpUx9DnQUkA    4635\n",
      "8FJEtCvb2Kw    3668\n",
      "b8o7LzGqc3E    2047\n",
      "UkfgB48jeZA    1872\n",
      "pFMiuAtbMO0    1551\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Maggie_Mae_Fish\n",
      "\n",
      "aJ0nAkXOkMs    177\n",
      "inXrIYr2V_U    174\n",
      "8DzSRkV_lTw    134\n",
      "HWKpo5n9bAQ     90\n",
      "SfP7sp0Zppw     71\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Magog_of_Morskar\n",
      "\n",
      "kq7fkcBK3LA    995\n",
      "kzRxiFt-4kA    921\n",
      "1yi2dW67mRg    798\n",
      "IDoVC_zYJCU    655\n",
      "qdfdUEEcXHQ    563\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "MovieBob\n",
      "\n",
      "gr7Sbu2Zgk4    995\n",
      "jrusTEvgxgI    929\n",
      "ApyNrbisJ_c    826\n",
      "3jV7HFrYIyc    777\n",
      "RdkYCpQ2TNY    701\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "NerdSync\n",
      "\n",
      "ST5WwIFo1TM    124\n",
      "IbLbEYuDZEA     53\n",
      "pn6HacKsbOQ     13\n",
      "WOgP2IQOK-I     12\n",
      "TiUJcTSYdL0     10\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Nyx_Fears\n",
      "\n",
      "sd_YNMEZndA    2510\n",
      "F_eJr3GpnY4     497\n",
      "WGLDKVUJbkw     417\n",
      "wO8sO17r8G4     341\n",
      "67LhpG_BzJY     333\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Petscop\n",
      "\n",
      "PiH04RGXYKo    1477\n",
      "OPzYMFdyKQQ     926\n",
      "6e6RK8o1fcs     153\n",
      "teJDdkWHAdw     102\n",
      "nXHUw2nw6aA      90\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Polygon\n",
      "\n",
      "PWwvR6cSH4o    3526\n",
      "FWzCy5-isjk    2912\n",
      "8Kb_WBChA5U    1531\n",
      "Emi74MDRMV8    1333\n",
      "eODyU0wa-to    1292\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Queer_Kid_Stuff\n",
      "\n",
      "None    27\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Radekken\n",
      "\n",
      "4Uba87MYwSY    1498\n",
      "4ea1Qdh-SzY    1279\n",
      "jF0dbw0B84s    1096\n",
      "tgHMPu2evko     873\n",
      "nnhpE06SU5Y     693\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Sammus\n",
      "\n",
      "Zzx0d3pZbdA    142\n",
      "s64aSHOk3bg    137\n",
      "bjhRvQM-wiw    133\n",
      "IuxwLV-13bQ     96\n",
      "tNMngwHWxHE     93\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Shodan\n",
      "\n",
      "5CyVciSPwf0    57\n",
      "None            8\n",
      "sAFcQA5_6f8     6\n",
      "f9dftpqTDVs     6\n",
      "dDsfmiuKp0E     6\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Small_Beans\n",
      "\n",
      "GNdwD8gQbSU    874\n",
      "1ASWLshamUM    571\n",
      "z80bqIcJQZo    385\n",
      "D0ilHoltkEI    117\n",
      "LVjEWjRxTVU    104\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Some_More_News\n",
      "\n",
      "hYAYFgmOWAI    2229\n",
      "CcklYVR5I-I    1347\n",
      "7JdQIe9z7IM    1301\n",
      "DJFFls6mBb8    1255\n",
      "fIN8oxnw__I    1191\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Strange_Aeons\n",
      "\n",
      "RgyROYtnWtk    2356\n",
      "DO5d4PYyn4g     549\n",
      "ZpqeFjoJyos     470\n",
      "aYn8XRRcSpg     306\n",
      "m5G2Yt4u988     264\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "Super_Bunnyhop\n",
      "\n",
      "88_4E4RsO58    562\n",
      "pwgYgid6T6Q    473\n",
      "-kE9BR24XIw    461\n",
      "pyPW4g6H66w    392\n",
      "18074QFwdmE    319\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "The_Gaming_Brit_Show\n",
      "\n",
      "pX4mhp-8sOc    14569\n",
      "houDtgBNPCA     6285\n",
      "3kD_QhYgIA4     4278\n",
      "b0a_QlurNZU     3882\n",
      "SfS0254dRRw     3339\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "The_Golden_One\n",
      "\n",
      "pG8a2PyGYGk    854\n",
      "lpa26rxwhyY    666\n",
      "CZaG6n4oHiI    498\n",
      "NNNykEpTyTU    440\n",
      "749m_bhC_j0    299\n",
      "Name: video_id, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(channels_obtained)):\n",
    "    print(channel_names[i])\n",
    "    print(\"\")\n",
    "#    print('Top 5:')\n",
    "    print(channels_obtained[i]['video_id'].value_counts().head(5))\n",
    "    print(\"\")\n",
    "#    print('Bottom 5:')\n",
    "#    print(all_channels_we_have[i]['video_id'].value_counts().tail(5))\n",
    "#    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Bob We Trust - SHOULD DISNEY REHIRE JAMES GUNN? #RehireJamesGunn'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtain_video_title('gr7Sbu2Zgk4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_counts(df):\n",
    "    print(\"Total     Likes:\", df['likes'].sum())\n",
    "    print(\"Total   Replies:\", df['replies'].sum())\n",
    "    print(\"Total  Comments:\", df.shape[0])\n",
    "    print(\"Hidden Comments:\", df.shape[0] - df['is_public'].sum())\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK\n",
    "from nltk.tokenize import RegexpTokenizer  # Tokenizer\n",
    "from nltk.stem import PorterStemmer        # Stemmer\n",
    "from nltk.corpus import stopwords          # Stopwords\n",
    "import re                                  # Regex?\n",
    "\n",
    "from gensim import corpora, models         # Modeling\n",
    "import pyLDAvis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "doc2bow expects an array of unicode tokens on input, not a single string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-602c8bf405e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#np.random.seed(76)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprune_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;31m# update Dictionary with the document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ignore the result, here we only care about updating token ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36mdoc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"doc2bow expects an array of unicode tokens on input, not a single string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Construct (word, frequency) mapping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: doc2bow expects an array of unicode tokens on input, not a single string"
     ]
    }
   ],
   "source": [
    "                                            # LDA Visualizations from Mark\n",
    "\n",
    "# NLTK\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Example Model\n",
    "\n",
    "doc_1 = 'I like to eat broccoli and bananas.'\n",
    "doc_2 = 'I ate a banana and spinach smoothie for breakfast.'\n",
    "doc_3 = 'Chinchillas and kittens are cute.'\n",
    "doc_4 = 'My sister adopted a kitten yesterday.'\n",
    "doc_5 = 'Look at this cute hamster munching on a piece of broccoli.'\n",
    "\n",
    "## Step 1: Preprocess our text.\n",
    "def text_process(text):                                               # Potentially using other processer\n",
    "    if pd.isnull(text):                                               # Removes Nulls\n",
    "        return []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')                               # Tokenize & removing punctuation\n",
    "    text_p=tokenizer.tokenize(text)\n",
    "    text_p = [word.lower() for word in text_p if word.lower() not in stopwords.words('english')] # Stopwords\n",
    "    porter_stemmer = PorterStemmer()                                  # Stemming\n",
    "    text_p = [porter_stemmer.stem(word) for word in text_p]\n",
    "    try:\n",
    "        text_p.remove('b')                                            # Dunno wtf this even is\n",
    "    except: \n",
    "        pass\n",
    "    return text_processed\n",
    "\n",
    "texts = [text_process(doc_1),\n",
    "         text_process(doc_2),\n",
    "         text_process(doc_3),\n",
    "         text_process(doc_4),\n",
    "         text_process(doc_5)]\n",
    "\n",
    "texts = Allison['text']\n",
    "\n",
    "## Step 2: Fit LDA Model.\n",
    "\n",
    "from gensim import corpora, models\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook() # in order for our visual to show up\n",
    "\n",
    "#np.random.seed(76)\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "for text in texts:\n",
    "    print(dictionary.doc2bow(text))\n",
    "\n",
    "ldamodel = models.ldamodel.LdaModel(corpus,\n",
    "                                    id2word = dictionary,       # connect each word to its \"spot\" in dictionary\n",
    "                                    num_topics = 2,             # hyperparameter T for number of topics\n",
    "                                    passes = 5,                 # Times do we iterate through the data\n",
    "                                    minimum_probability = 0.01) # only include topics w/probability threshold\n",
    "\n",
    "\n",
    "\n",
    "#ldamodel.\n",
    "\n",
    "## Step 3: Visualize LDA model.\n",
    "\n",
    "pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n",
    "\n",
    "# Instantiations\n",
    "porter_stemmer = PorterStemmer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def stemming_function(text):\n",
    "    text_processed = tokenizer.tokenize(text)\n",
    "    text_processed = [porter_stemmer.stem(word) for word in text_processed]\n",
    "    return text_processed\n",
    "cvec = CountVectorizer(analyzer = \"word\",\n",
    "                             min_df = 2,\n",
    "                             tokenizer = tokenizer.tokenize,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = 'english') \n",
    "\n",
    "# NLTK\n",
    "from nltk.stem import PorterStemmer\n",
    "from gensim import corpora#, models,\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def LDA_visualized(df, num_topics = 3, num_words = 5):\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics)\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    cvec.fit(df['text'])\n",
    "    text = cvec.transform(df['text'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    lda.fit(text)\n",
    "    \n",
    "    \n",
    "    for ix, topic in enumerate(lda.components_):\n",
    "        print('Topic ', ix + 1)\n",
    "        top_words = [cvec.get_feature_names()[i] for i in lda.components_[ix].argsort()[:-num_words - 1:-1]]\n",
    "        print('\\n'.join(top_words))\n",
    "        print('\\n')\n",
    "    return\n",
    "\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "ldamodel = models.ldamodel.LdaModel(corpus,\n",
    "                                    id2word = dictionary,       # connect each word to its \"spot\" in dictionary\n",
    "                                    num_topics = 2,             # hyperparameter T for number of topics\n",
    "                                    passes = 5,                 # Times do we iterate through the data\n",
    "                                    minimum_probability = 0.01) # only include topics w/probability threshold\n",
    "\n",
    "\n",
    "## Step 3: Visualize LDA model.\n",
    "pyLDAvis.sklearn.prepare(ldamodel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the comments of specific videos\n",
    "df_Breath_Of_The_Wild_28_Game_Grumps = pd.read_csv('./data/Breath_Of_The_Wild_28_Game_Grumps_9_22')\n",
    "df_Breath_Of_The_Wild_EYE_45 = pd.read_csv('./data/Breath_Of_The_Wild_EYE_45_Game_Grumps_9_22')\n",
    "df_Danny_Dont_You_Know = pd.read_csv('./data/Danny_Dont_You_Know_9_22')\n",
    "df_How_to_Gay_Date = pd.read_csv('./data/How_to_Gay_Date_9_22')\n",
    "df_Incels_ContraPoints = pd.read_csv('./data/Incels_ContraPoints_9_23')\n",
    "df_Incels_Investigating_Toxic_Forums_Strange_Aeons = pd.read_csv('./data/Incels_Investigating_Toxic_Forums_Strange_Aeons_9_23')\n",
    "df_Incels_This_is_What_The_Life_Of_An_Looks_Like_HBO = pd.read_csv('./data/Incels_This_is_What_The_Life_Of_An_Looks_Like_HBO_9_23')\n",
    "df_Incels_Types_of_BasedShaman = pd.read_csv('./data/Incels_Types_of_BasedShaman_9_23')\n",
    "df_Lets_Talk_About_Thanos = pd.read_csv('./data/Lets_Talk_About_Thanos_9_22')\n",
    "df_Orisa_Tip_for_Every_Hero = pd.read_csv('./data/Orisa_Tip_for_Every_Hero_9_22')\n",
    "df_Siblings_Play_Truth_or_Drink = pd.read_csv('./data/Siblings_Play_Truth_or_Drink_9_22')\n",
    "df_Specter_of_Torment_1_Game_Grumps = pd.read_csv('./data/Specter_of_Torment_1_Game_Grumps_9_22')\n",
    "df_Spinning_Webs_Lucas_The_Spider = pd.read_csv('./data/Spinning_Webs_Lucas_The_Spider_9_22')\n",
    "df_The_Aesthetic = pd.read_csv('./data/The_Aesthetic_9_22')\n",
    "df_Blockchain_Games_NewDan_Extra_Credits = pd.read_csv('./data/Blockchain_Games_NewDan_Extra_Credits_9_27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_video_title(vid_id):\n",
    "    if vid_id == 'None':\n",
    "        return \"Discussion Comment\"\n",
    "    else:\n",
    "        endpoint = 'https://www.googleapis.com/youtube/v3/videos'\n",
    "        params = {\n",
    "            'part':'snippet',\n",
    "            'id':str(vid_id),\n",
    "            'key':'AIzaSyCruFbHTolS_lK_AHrakQrjSVLzdEO5MaI'\n",
    "        }\n",
    "\n",
    "        res = requests.get(url=endpoint,params=params)\n",
    "        return res.json()['items'][0]['snippet']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
